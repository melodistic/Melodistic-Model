{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model,Model\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "from spleeter.separator import Separator\n",
    "import shutil\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_instrumental(separator,audio,name):\n",
    "    # Wait for implementation\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio():\n",
    "    # Wait for implementation\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    # Wait for implementation\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bpm(path):\n",
    "    path = 'extract/' + path + '.wav'\n",
    "    y, sr = librosa.load(path)\n",
    "    tempo, _ = librosa.beat.beat_track(y,sr)\n",
    "    del y, sr\n",
    "    gc.collect()\n",
    "    return tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(path):\n",
    "    path = \"spectogram/\" + path + \".png\"\n",
    "    IMAGE_SIZE = 224\n",
    "    img = tf.keras.preprocessing.image.load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
    "    )\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array / 255\n",
    "    img_array = img_array.reshape(1,IMAGE_SIZE,IMAGE_SIZE,3)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate_audio(filepath):\n",
    "    # Wait for implementation\n",
    "    # extract_instrumental(audio)\n",
    "    # extract_audio()\n",
    "    audio_list = []\n",
    "    for mood in os.listdir(\"spectogram\"):\n",
    "        for file in os.listdir(\"spectogram/\"+mood):\n",
    "            audio_list.append(mood+\"/\"+file.split(\".\")[0])\n",
    "    return audio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model_path = 'models/model_v1.h5'\n",
    "    model = load_model(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,audio):\n",
    "    class_labels = [\"Anxious\",\"Chill\",\"Focus\",\"Party\",\"Romance\",\"Sad\"]\n",
    "    predictions = model.predict(audio)\n",
    "    mood = class_labels[np.argmax(predictions)]   \n",
    "    feature_model = Model(model.input,model.layers[-6].output)\n",
    "    features = feature_model.predict(audio)\n",
    "    return mood,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'features/Love Me Now_11.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=8'>9</a>\u001b[0m mood, features \u001b[39m=\u001b[39m prediction(model,spectrogram)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=9'>10</a>\u001b[0m data\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmusic_name\u001b[39m\u001b[39m\"\u001b[39m:audio\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=11'>12</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmusic_path\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msong/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m audio \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=14'>15</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmood\u001b[39m\u001b[39m\"\u001b[39m:mood,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_system\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=16'>17</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mfeatures/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m audio\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.json\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=17'>18</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(features\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist(), f)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ggolfz/Desktop/capstone-project/melodistic-model/deployment.ipynb#ch0000009?line=18'>19</a>\u001b[0m     f\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features/Love Me Now_11.json'"
     ]
    }
   ],
   "source": [
    "filepath = \"\"\n",
    "model = get_model()\n",
    "audios = manipulate_audio(filepath)\n",
    "data = []\n",
    "i = 0\n",
    "for audio in audios:\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    bpm = get_bpm(audio)\n",
    "    mood, features = prediction(model,spectrogram)\n",
    "    data.append({\n",
    "        \"music_name\":audio.split(\"/\")[1],\n",
    "        \"music_path\": \"song/\" + audio + \".wav\",\n",
    "        \"music_feature_path\": \"features/\" + audio.split(\"/\")[1] + \".json\",\n",
    "        \"bpm\":bpm,\n",
    "        \"mood\":mood,\n",
    "        \"is_system\": True})\n",
    "    with open(\"features/\" + audio.split(\"/\")[1] + \".json\", 'w') as f:\n",
    "        json.dump(features.flatten().tolist(), f)\n",
    "        f.close()\n",
    "    del spectrogram, mood, bpm, features\n",
    "    gc.collect()\n",
    "    i+=1\n",
    "    print(str(i)+\"/\"+str(len(audios)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"music.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mood_list = [\"Anxious\",\"Chill\",\"Focus\",\"Party\",\"Romance\",\"Sad\"]\n",
    "for mood in mood_list:\n",
    "    data = json.load(open(mood + \".json\"))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(mood + \".csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb7f5d246b341b988358d618623402cd5f4df3fd9724cd461a5bf09489b82624"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
